# # main.py ‚Äì PHI√äN B·∫¢N HO√ÄN CH·ªàNH (sau khi n√¢ng c·∫•p: query rewriting cho ng·ªØ c·∫£nh + c·∫£i thi·ªán retrieval cho details + ch·ªânh prompt)
# from fastapi import FastAPI, HTTPException
# from fastapi.middleware.cors import CORSMiddleware
# from pydantic import BaseModel
# from typing import List, Optional, Dict, Any
# import uvicorn
# import os
# from pathlib import Path
# import uuid
# import json
# from functools import lru_cache
# from langchain_huggingface import HuggingFaceEmbeddings
# from langchain_community.vectorstores import FAISS
# from langchain_core.prompts import ChatPromptTemplate
# from langchain_core.documents import Document
# from langchain_core.runnables import RunnableParallel
# from langchain_core.output_parsers import StrOutputParser
# from langchain_core.messages import HumanMessage, AIMessage
# from langchain_community.chat_message_histories import ChatMessageHistory
# from langchain_openai import ChatOpenAI, OpenAIEmbeddings
# # ==========================================================
# # APP + CORS
# # ==========================================================
# app = FastAPI(title="Shop C·∫ßu L√¥ng AI ‚Äì Linh Nh·ªõ L√¢u, Si√™u Th√¢n Thi·ªán")
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["http://localhost:3000"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
# # ==========================================================
# # CONFIG
# # ==========================================================
# DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-72fc18a871824e58a910a499f281512c")
# DB_FOLDER = Path("faiss_shopcaulong")
# DB_FOLDER.mkdir(exist_ok=True)
# HISTORY_FILE = Path("chat_history.json") # L∆∞u l·ªãch s·ª≠ chat vƒ©nh vi·ªÖn
# vectorstore: FAISS | None = None
# qa_chain = None
# qa_chain_fallback = None
# store: Dict[str, ChatMessageHistory] = {}
# product_doc_ids = {}
# # ==========================================================
# # L∆ØU & LOAD L·ªäCH S·ª¨ CHAT
# # ==========================================================
# def load_history():
#     global store
#     if HISTORY_FILE.exists():
#         try:
#             data = json.loads(HISTORY_FILE.read_text(encoding="utf-8"))
#             for session_id, messages in data.items():
#                 history = ChatMessageHistory()
#                 for msg in messages:
#                     if msg["type"] == "human":
#                         history.add_message(HumanMessage(content=msg["content"]))
#                     else:
#                         history.add_message(AIMessage(content=msg["content"]))
#                 store[session_id] = history
#             print(f"ƒê√£ kh√¥i ph·ª•c l·ªãch s·ª≠ c·ªßa {len(store)} phi√™n chat")
#         except Exception as e:
#             print("L·ªói load l·ªãch s·ª≠ chat:", e)
# def save_history():
#     data = {}
#     for session_id, history in store.items():
#         data[session_id] = [
#             {"type": "human" if isinstance(m, HumanMessage) else "ai", "content": m.content}
#             for m in history.messages
#         ]
#     try:
#         HISTORY_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
#     except Exception as e:
#         print("L·ªói l∆∞u l·ªãch s·ª≠ chat:", e)
# def get_session_history(session_id: str) -> ChatMessageHistory:
#     if session_id not in store:
#         store[session_id] = ChatMessageHistory()
#     return store[session_id]
# # ==========================================================
# # EMBEDDING & LLM
# # ==========================================================
# @lru_cache()
# def get_embedding():
#     openai_key = os.getenv("OPENAI_API_KEY")
#     if openai_key:
#         try:
#             print("üîπ ƒêang s·ª≠ d·ª•ng OpenAI Embeddings (text-embedding-3-small)...")
#             return OpenAIEmbeddings(
#                 model="text-embedding-3-small",
#                 api_key=openai_key,
#                 max_retries=2,
#             )
#         except Exception as e:
#             print("L·ªói OpenAI Embedding, chuy·ªÉn qua HuggingFace:", e)
#     print("üîπ Fallback sang HuggingFace Embedding (multilingual-e5-small)")
#     return HuggingFaceEmbeddings(
#         model_name="intfloat/multilingual-e5-small",
#         model_kwargs={"device": "cpu"},
#         encode_kwargs={"normalize_embeddings": True},
#     )
# @lru_cache()
# def get_llm():
#     print("üîπ Kh·ªüi t·∫°o DeepSeek LLM...")
#     return ChatOpenAI(
#         model="deepseek-chat",
#         temperature=0.3,
#         max_tokens=600,
#         api_key=DEEPSEEK_API_KEY,
#         base_url="https://api.deepseek.com",
#         timeout=20,
#         max_retries=2,
#     )
# # ==========================================================
# # DATA MODELS
# # ==========================================================
# class SizeVariant(BaseModel):
#     size: str
#     stock: int
# class ColorVariant(BaseModel):
#     color: str
#     imageUrls: List[str] = []
#     sizes: List[SizeVariant]
# class Product(BaseModel):
#     id: int
#     name: str
#     description: str = ""
#     price: float
#     discountPrice: Optional[float] = None
#     stock: int
#     brandName: str
#     categoryName: str
#     isFeatured: bool = False
#     details: List[Dict[str, Any]] = []
#     colorVariants: List[ColorVariant] = []
# # ==========================================================
# def create_product_documents(product: Product) -> List[Document]:
#     price = product.discountPrice or product.price
#     product_id = product.id
#     product_url = f"http://localhost:3000/product/{product_id}"
#     docs = []
#     # ‚îÄ‚îÄ 1. Chunk t·ªïng quan (gi·ªØ nguy√™n nh∆∞ng t·ªëi ∆∞u h∆°n ch√∫t)
#     info_text = f"{product.name} | {product.brandName} | {product.categoryName}"
#     info_text += f" | Gi√°: {price:,.0f}ƒë"
#     if product.discountPrice:
#         info_text += f" (gi·∫£m c√≤n {product.discountPrice:,.0f}ƒë)"
#     if product.description:
#         info_text += f"\nM√¥ t·∫£ ng·∫Øn: {product.description.strip()}"
#     info_text += f"\nChi ti·∫øt ƒë·∫ßy ƒë·ªß: {product_url}"
#     docs.append(Document(
#         page_content=info_text.strip(),
#         metadata={
#             "product_id": product_id,
#             "type": "overview",
#             "url": product_url
#         }
#     ))
#     # ‚îÄ‚îÄ 2. Chunk bi·∫øn th·ªÉ m√†u + size (gi·ªØ nguy√™n logic)
#     for cv in product.colorVariants or []:
#         color = (cv.color or "kh√¥ng m√†u").strip()
#         available_sizes = [s.size for s in (cv.sizes or []) if s.stock > 0]
#         if available_sizes:
#             sizes_str = ", ".join(available_sizes)
#             variant_text = (
#                 f"{product.name} m√†u {color} c√≤n size {sizes_str} "
#                 f"gi√° {price:,.0f}ƒë. Xem chi ti·∫øt: {product_url}"
#             )
#             docs.append(Document(
#                 page_content=variant_text,
#                 metadata={
#                     "product_id": product_id,
#                     "type": "variant",
#                     "color": color,
#                     "url": product_url
#                 }
#             ))
#     # ‚îÄ‚îÄ 3. Chunk chi ti·∫øt k·ªπ thu·∫≠t (c·∫£i thi·ªán: th√™m keyword ƒë·ªÉ d·ªÖ retrieve h∆°n)
#     for idx, detail in enumerate(product.details or [], 1):
#         text = detail.get("Text")
#         image = detail.get("ImageUrl")
#         sort_order = detail.get("SortOrder", idx)
#         if not text or not isinstance(text, str) or len(text.strip()) < 10:
#             continue # b·ªè qua block r·ªóng ho·∫∑c qu√° ng·∫Øn
#         # T·∫°o n·ªôi dung chunk chi ti·∫øt v·ªõi keyword r√µ r√†ng
#         detail_content = f"Th√¥ng s·ªë k·ªπ thu·∫≠t v√† chi ti·∫øt {product.name} (block {sort_order}):\n"
#         detail_content += text.strip()
#         # N·∫øu c√≥ ·∫£nh th√¨ th√™m th√¥ng tin tham kh·∫£o (kh√¥ng b·∫Øt bu·ªôc)
#         if image and isinstance(image, str):
#             detail_content += f"\n[H√¨nh minh h·ªça: {image}]"
#         detail_content += f"\nXem ƒë·∫ßy ƒë·ªß s·∫£n ph·∫©m: {product_url}"
#         docs.append(Document(
#             page_content=detail_content.strip(),
#             metadata={
#                 "product_id": product_id,
#                 "type": "detail",
#                 "block_order": sort_order,
#                 "has_image": bool(image),
#                 "url": product_url
#             }
#         ))
#     return docs
# # ==========================================================
# # X√ìA CHUNKS C·ª¶A S·∫¢N PH·∫®M
# # ==========================================================
# def delete_product_chunks(product_id: int) -> int:
#     if not vectorstore or vectorstore.index.ntotal == 0:
#         return 0
#     if product_id in product_doc_ids:
#         ids_to_delete = product_doc_ids[product_id]
#         vectorstore.delete(ids_to_delete)
#         del product_doc_ids[product_id]
#         return len(ids_to_delete)
#     # Fallback
#     ids_to_delete = []
#     for i in range(vectorstore.index.ntotal):
#         doc_id = vectorstore.index_to_docstore_id[i]
#         doc = vectorstore.docstore.search(doc_id)
#         if isinstance(doc, Document) and doc.metadata.get("product_id") == product_id:
#             ids_to_delete.append(doc_id)
#     if ids_to_delete:
#         vectorstore.delete(ids_to_delete)
#     return len(ids_to_delete)
# # ==========================================================
# # PROMPTS (ƒë·ªãnh nghƒ©a tr∆∞·ªõc khi build chain)
# # ==========================================================
# template_with_products = """
# B·∫°n l√† Linh ‚Äì nh√¢n vi√™n t∆∞ v·∫•n c·ªßa Shop C·∫ßu L√¥ng Pro.
# D·ªÆ LI·ªÜU S·∫¢N PH·∫®M TRONG KHO:
# {context}
# L·ªäCH S·ª¨ H·ªòI THO·∫†I G·∫¶N ƒê√ÇY:
# {history}
# C√ÇU H·ªéI C·ª¶A KH√ÅCH:
# {question}
# QUY T·∫ÆC TR·∫¢ L·ªúI:
# 1. Ch·ªâ d√πng th√¥ng tin t·ª´ "D·ªÆ LI·ªÜU S·∫¢N PH·∫®M TRONG KHO"
# 2. Ch·ªâ d√πng ƒë√∫ng link xu·∫•t hi·ªán trong d·ªØ li·ªáu: [xem chi ti·∫øt](URL)
# 3. G·ª£i √Ω t·ªëi ƒëa 3 s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t
# 4. G·ªôp m√†u/size c·ªßa c√πng s·∫£n ph·∫©m
# 5. Gi·ªçng ƒëi·ªáu th√¢n thi·ªán, t·ª± nhi√™n, h·∫°n ch·∫ø emoji
# 6. N·∫øu h·ªèi v·ªÅ th√¥ng s·ªë k·ªπ thu·∫≠t, s·ª≠ d·ª•ng chi ti·∫øt t·ª´ c√°c block "Th√¥ng s·ªë k·ªπ thu·∫≠t v√† chi ti·∫øt" trong d·ªØ li·ªáu
# 7. C√≥ th·ªÉ ƒë∆∞a th√™m 1-2 c√¢u h·ªèi g·ª£i √Ω ƒë·ªÉ kh√°ch h·ªèi ti·∫øp
# TR·∫¢ L·ªúI:
# """
# template_fallback = """
# B·∫°n l√† Linh ‚Äì m·ªôt c√¥ g√°i tr·∫ª trung, th√¢n thi·ªán, nhi·ªát t√¨nh, l√†m tr·ª£ l√Ω cho Shop C·∫ßu L√¥ng Pro.
# Shop chuy√™n b√°n v·ª£t, gi√†y, c∆∞·ªõc, c·∫ßu, ph·ª• ki·ªán c·∫ßu l√¥ng ch√≠nh h√£ng (Yonex, Victor, Lining...), nh∆∞ng Linh r·∫•t vui khi tr√≤ chuy·ªán v·ªÅ b·∫•t k·ª≥ ch·ªß ƒë·ªÅ n√†o v·ªõi kh√°ch h√†ng ‚Äì t·ª´ th·ªÉ thao kh√°c, s·∫£n ph·∫©m ngo√†i l·ªÅ, ƒë·∫øn chuy·ªán ƒë·ªùi th∆∞·ªùng, t√¨nh c·∫£m, c√¥ng vi·ªác...
# L·ªäCH S·ª¨ TR√í CHUY·ªÜN G·∫¶N ƒê√ÇY (ƒë·ªçc k·ªπ ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh v√† tone hi·ªán t·∫°i):
# {history}
# C√ÇU H·ªéI HO·∫∂C TIN NH·∫ÆN M·ªöI NH·∫§T C·ª¶A KH√ÅCH:
# {question}
# T√åNH HU·ªêNG HI·ªÜN T·∫†I: Kh√¥ng t√¨m th·∫•y th√¥ng tin s·∫£n ph·∫©m ph√π h·ª£p tr·ª±c ti·∫øp t·ª´ kho c·∫ßu l√¥ng.
# C√ÅCH TR·∫¢ L·ªúI T·ªêT NH·∫§T:
# - ƒê·ªçc l·ªãch s·ª≠ ƒë·ªÉ n·∫Øm tone cu·ªôc tr√≤ chuy·ªán (th√¢n m·∫≠t, nghi√™m t√∫c, vui v·∫ª, ƒëang h·ªèi mua hay ch·ªâ h·ªèi ch∆°i...).
# - Tr·∫£ l·ªùi **t·ª± nhi√™n nh∆∞ ƒëang chat v·ªõi b·∫°n**, kh√¥ng c·∫ßn b·∫Øt ƒë·∫ßu b·∫±ng "Ch√†o b·∫°n" m·ªói l·∫ßn n·∫øu l·ªãch s·ª≠ ƒë√£ th√¢n thi·∫øt.
# - Tr·∫£ l·ªùi **h·ªØu √≠ch, ch√¢n th·ª±c** d·ª±a tr√™n ki·∫øn th·ª©c chung. N·∫øu l√† s·∫£n ph·∫©m m√¥n kh√°c (gi√†y b√≥ng ƒë√°, v·ª£t tennis...), c·ª© g·ª£i √Ω tho·∫£i m√°i d·ª±a tr√™n th√¥ng tin ph·ªï bi·∫øn, kh√¥ng c·∫ßn b·ªãa gi√°/link.
# - N·∫øu nh·∫Øc ƒë·∫øn shop, ch·ªâ n√≥i nh·∫π nh√†ng khi th·∫≠t s·ª± li√™n quan (v√≠ d·ª•: "Shop m√¨nh chuy√™n c·∫ßu l√¥ng n√™n kh√¥ng c√≥ c√°i n√†y, nh∆∞ng n·∫øu b·∫°n c·∫ßn... th√¨ Linh t∆∞ v·∫•n li·ªÅn nh√©!"). ƒê·ª´ng nh·∫Øc l·∫∑p l·∫°i n·∫øu l·ªãch s·ª≠ ƒë√£ n√≥i r·ªìi.
# - T·ª´ "b√≥ng" ‚Üí m·∫∑c ƒë·ªãnh hi·ªÉu l√† **c·∫ßu** (shuttlecock) n·∫øu ƒëang n√≥i v·ªÅ c·∫ßu l√¥ng, ch·ªâ hi·ªÉu l√† b√≥ng ƒë√° khi ng·ªØ c·∫£nh r√µ r√†ng (s√¢n c·ªè, s√∫t b√≥ng, gi√†y ƒë√° b√≥ng...).
# - Gi·ªØ gi·ªçng ƒëi·ªáu vui v·∫ª, g·∫ßn g≈©i, kh√¥ng d√πng emoji tr·ª´ khi l·ªãch s·ª≠ c√≥ d√πng nhi·ªÅu.
# - K·∫øt th√∫c b·∫±ng c√¢u h·ªèi ho·∫∑c g·ª£i √Ω t·ª± nhi√™n ƒë·ªÉ ti·∫øp t·ª•c cu·ªôc tr√≤ chuy·ªán (kh√¥ng √©p bu·ªôc, t√πy theo flow).
# H√£y tr·∫£ l·ªùi sao cho kh√°ch c·∫£m th·∫•y Linh ƒëang th·ª±c s·ª± l·∫Øng nghe v√† quan t√¢m ƒë·∫øn h·ªç nh√©!
# TR·∫¢ L·ªúI:
# """
# template_rewrite = """
# D·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn ƒë√¢y:
# {history}

# V√† c√¢u h·ªèi hi·ªán t·∫°i c·ªßa kh√°ch: {question}

# H√£y vi·∫øt l·∫°i c√¢u h·ªèi th√†nh m·ªôt c√¢u h·ªèi ƒë·ªôc l·∫≠p, ƒë·∫ßy ƒë·ªß th√¥ng tin, kh√¥ng c·∫ßn tham chi·∫øu ƒë·∫øn l·ªãch s·ª≠ (nh∆∞ "n√†y", "tr√™n", "ƒë√≥"). Bao g·ªìm t√™n s·∫£n ph·∫©m c·ª• th·ªÉ n·∫øu l·ªãch s·ª≠ ƒë·ªÅ c·∫≠p.

# V√≠ d·ª•:
# - L·ªãch s·ª≠: Kh√°ch h·ªèi v·ªÅ v·ª£t Yonex Astrox 99, b·∫°n g·ª£i √Ω n√≥.
# - C√¢u h·ªèi: "Th√¥ng s·ªë k·ªπ thu·∫≠t c·ªßa v·ª£t tr√™n l√† g√¨?"
# - Vi·∫øt l·∫°i: "Th√¥ng s·ªë k·ªπ thu·∫≠t c·ªßa v·ª£t Yonex Astrox 99 l√† g√¨?"

# N·∫øu c√¢u h·ªèi ƒë√£ ƒë·ªôc l·∫≠p v√† kh√¥ng c·∫ßn ng·ªØ c·∫£nh, gi·ªØ nguy√™n.
# Ch·ªâ tr·∫£ v·ªÅ c√¢u h·ªèi ƒë√£ vi·∫øt l·∫°i, kh√¥ng gi·∫£i th√≠ch.
# """
# prompt_with_products = ChatPromptTemplate.from_template(template_with_products)
# prompt_fallback = ChatPromptTemplate.from_template(template_fallback)
# prompt_rewrite = ChatPromptTemplate.from_template(template_rewrite)
# # ==========================================================
# # BUILD QA CHAIN
# # ==========================================================
# def build_qa_chain():
#     global qa_chain, qa_chain_fallback
#     if not vectorstore or vectorstore.index.ntotal == 0:
#         qa_chain = None
#         qa_chain_fallback = None
#         return
#     # Retriever c∆° b·∫£n v·ªõi threshold th·∫•p h∆°n ƒë·ªÉ l·∫•y nhi·ªÅu detail h∆°n (t·ª´ 0.35 xu·ªëng 0.3)
#     retriever = vectorstore.as_retriever(
#         search_type="similarity_score_threshold",
#         search_kwargs={"k": 15, "score_threshold": 0.3}  # TƒÉng k=15, h·∫° threshold ƒë·ªÉ d·ªÖ l·∫•y detail
#     )
#     # Chain ch√≠nh (c√≥ s·∫£n ph·∫©m)
#     qa_chain = (
#         RunnableParallel({
#             "context": lambda x: "\n".join([d.page_content for d in retriever.invoke(x["question"])]),
#             "question": lambda x: x["question"],
#             "history": lambda x: x.get("history", "Ch∆∞a c√≥ l·ªãch s·ª≠"),
#         })
#         | prompt_with_products
#         | get_llm()
#         | StrOutputParser()
#     )
#     # Chain fallback
#     qa_chain_fallback = (
#         RunnableParallel({
#             "question": lambda x: x["question"],
#             "history": lambda x: x.get("history", "Ch∆∞a c√≥ l·ªãch s·ª≠"),
#         })
#         | prompt_fallback
#         | get_llm()
#         | StrOutputParser()
#     )
# # ==========================================================
# # ROUTES
# # ==========================================================
# @app.get("/")
# async def root():
#     total = vectorstore.index.ntotal if vectorstore else 0
#     return {
#         "message": "Linh ƒëang online v√† nh·ªõ h·∫øt kh√°ch r·ªìi n√®!",
#         "chunks": total,
#         "active_sessions": len(store)
#     }
# @app.post("/debug_chunks")
# async def debug_chunks_post(
#     limit: int = 50,
#     product_id: Optional[int] = None,
#     include_metadata: bool = True
# ):
#     """
#     Xem t·∫•t c·∫£ chunk hi·ªán c√≥ trong FAISS (d√πng POST)
#     - limit: s·ªë l∆∞·ª£ng chunk t·ªëi ƒëa tr·∫£ v·ªÅ (m·∫∑c ƒë·ªãnh 50)
#     - product_id: l·ªçc theo s·∫£n ph·∫©m (n·∫øu c√≥)
#     - include_metadata: c√≥ hi·ªán metadata kh√¥ng
#     """
#     if not vectorstore or vectorstore.index.ntotal == 0:
#         return {
#             "total_chunks_in_db": 0,
#             "returned_chunks": 0,
#             "chunks": [],
#             "message": "Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c chunk"
#         }
   
#     total = vectorstore.index.ntotal
#     results = []
   
#     for i in range(min(limit, total)):
#         doc_id = vectorstore.index_to_docstore_id[i]
#         doc = vectorstore.docstore.search(doc_id)
       
#         if isinstance(doc, Document):
#             item = {
#                 "index": i,
#                 "content": doc.page_content
#             }
#             if include_metadata:
#                 item["metadata"] = doc.metadata
           
#             # L·ªçc theo product_id n·∫øu c√≥
#             if product_id is not None:
#                 if doc.metadata.get("product_id") != product_id:
#                     continue
           
#             results.append(item)
   
#     return {
#         "total_chunks_in_db": total,
#         "returned_chunks": len(results),
#         "chunks": results,
#         "message": f"ƒê√£ chunk {total} m·∫©u d·ªØ li·ªáu t·ª´ s·∫£n ph·∫©m"
#     }
# @app.post("/add_product")
# async def add_product(product: Product):
#     global vectorstore
   
#     delete_product_chunks(product.id)
#     docs = create_product_documents(product)
   
#     if vectorstore is None:
#         vectorstore = FAISS.from_documents(docs, get_embedding())
#     else:
#         doc_ids = vectorstore.add_documents(docs)
#         product_doc_ids[product.id] = doc_ids
   
#     vectorstore.save_local(str(DB_FOLDER))
#     build_qa_chain()
   
#     return {"status": "OK", "message": f"ƒê√£ th√™m {product.name}"}
# @app.post("/update_product")
# async def update_product(product: Product):
#     global vectorstore
   
#     print(f"[AI] Nh·∫≠n y√™u c·∫ßu update s·∫£n ph·∫©m ID: {product.id} - {product.name}")
   
#     delete_product_chunks(product.id)
#     docs = create_product_documents(product)
   
#     if vectorstore is None:
#         vectorstore = FAISS.from_documents(docs, get_embedding())
#     else:
#         doc_ids = vectorstore.add_documents(docs)
#         product_doc_ids[product.id] = doc_ids
   
#     vectorstore.save_local(str(DB_FOLDER))
#     build_qa_chain()
   
#     print(f"[AI] ƒê√£ chunk {len(docs)} m·∫©u cho s·∫£n ph·∫©m {product.name}")
   
#     return {"status": "OK", "message": f"ƒê√£ c·∫≠p nh·∫≠t {product.name}"}
# @app.post("/delete_product")
# async def delete_product(product_id: int):
#     deleted = delete_product_chunks(product_id)
   
#     if deleted == 0:
#         raise HTTPException(404, "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m")
   
#     vectorstore.save_local(str(DB_FOLDER))
#     build_qa_chain()
   
#     return {"status": "OK", "deleted_chunks": deleted}
# @app.post("/reindex_all")
# async def rebuild(products: List[Product]):
#     global vectorstore, product_doc_ids
   
#     # Reset mapping m·ªõi
#     product_doc_ids = {}
   
#     # Gom to√†n b·ªô t√†i li·ªáu
#     all_docs = []
#     for p in products:
#         docs = create_product_documents(p)
#         all_docs.extend(docs)
#         product_doc_ids[p.id] = [] # t·∫°m t·∫°o danh s√°ch r·ªóng
   
#     # Build FAISS t·ª´ ƒë·∫ßu
#     vectorstore = FAISS.from_documents(all_docs, get_embedding())
   
#     # Sau khi build FAISS ‚Üí doc_ids ƒë∆∞·ª£c sinh theo th·ª© t·ª±
#     current_index = 0
#     for p in products:
#         docs_count = len(create_product_documents(p))
#         ids = []
#         for i in range(docs_count):
#             ids.append(vectorstore.index_to_docstore_id[current_index + i])
#         product_doc_ids[p.id] = ids
#         current_index += docs_count
   
#     # L∆∞u database
#     vectorstore.save_local(str(DB_FOLDER))
#     build_qa_chain()
   
#     return {"status": "OK", "chunks": len(all_docs)}
# # ==================== CHAT PAYLOAD ====================
# class ChatPayload(BaseModel):
#     question: str
#     session_id: Optional[str] = None
#     user_id: Optional[str] = None
# @app.post("/chat")
# async def chat(payload: ChatPayload):
#     if not qa_chain:
#         raise HTTPException(500, "Ch∆∞a c√≥ d·ªØ li·ªáu s·∫£n ph·∫©m!")
#     # X√°c ƒë·ªãnh session_id
#     if payload.user_id:
#         session_id = f"user_{payload.user_id}"
#     elif payload.session_id:
#         session_id = payload.session_id
#     else:
#         session_id = str(uuid.uuid4())
#     history = get_session_history(session_id)
#     history_str = "\n".join(
#         f"{'Kh√°ch' if isinstance(m, HumanMessage) else 'Linh'}: {m.content}"
#         for m in history.messages[-10:]
#     ) or "Ch∆∞a c√≥ l·ªãch s·ª≠"
#     # Query Classification
#     classify_prompt = ChatPromptTemplate.from_template("""
#         Ph√¢n lo·∫°i c√¢u h·ªèi: "{question}"
#         - N·∫øu li√™n quan ƒë·∫øn s·∫£n ph·∫©m c·∫ßu l√¥ng (v·ª£t, gi√†y, c∆∞·ªõc, t∆∞ v·∫•n mua h√†ng, so s√°nh s·∫£n ph·∫©m, th√¥ng s·ªë k·ªπ thu·∫≠t): tr·∫£ "relevant"
#         - N·∫øu kh√¥ng li√™n quan (h·ªèi t√¨nh y√™u, th·ªùi ti·∫øt, ch·ªß ƒë·ªÅ kh√°c): tr·∫£ "irrelevant"
#         Ch·ªâ tr·∫£ t·ª´ "relevant" ho·∫∑c "irrelevant", kh√¥ng gi·∫£i th√≠ch.
#     """)
#     classify_chain = classify_prompt | get_llm() | StrOutputParser()
#     classification = classify_chain.invoke({"question": payload.question}).strip().lower()
#     if classification == "irrelevant":
#         print("Query kh√¥ng li√™n quan ‚Üí direct fallback")
#         answer = qa_chain_fallback.invoke({"question": payload.question, "history": history_str})
#     else:
#         # Rewrite query ƒë·ªÉ x·ª≠ l√Ω ng·ªØ c·∫£nh (nh∆∞ "v·ª£t tr√™n")
#         rewrite_chain = prompt_rewrite | get_llm() | StrOutputParser()
#         standalone_question = rewrite_chain.invoke({"question": payload.question, "history": history_str}).strip()
#         print(f"Query g·ªëc: {payload.question} ‚Üí Standalone: {standalone_question}")
#         # Retrieve + ki·ªÉm tra context
#         retriever = vectorstore.as_retriever(search_kwargs={"k": 15})
#         try:
#             retrieved_docs = vectorstore.as_retriever(
#                 search_type="similarity_score_threshold",
#                 search_kwargs={"k": 15, "score_threshold": 0.3}
#             ).invoke(standalone_question)
#         except:
#             retrieved_docs = retriever.invoke(standalone_question)
#         context_text = "\n".join([d.page_content for d in retrieved_docs])
#         product_keywords = ["v·ª£t", "gi√†y", "c∆∞·ªõc", "yonex", "victor", "lining", "c√≤n h√†ng", "th√¥ng s·ªë", "chi ti·∫øt"]
#         has_products = len(retrieved_docs) > 0 and any(kw.lower() in context_text.lower() for kw in product_keywords)
#         print(f"S·ªë docs: {len(retrieved_docs)} | C√≥ s·∫£n ph·∫©m ph√π h·ª£p: {has_products}")
#         if has_products:
#             answer = qa_chain.invoke({"question": payload.question, "history": history_str, "context": context_text})  # S·ª≠ d·ª•ng question g·ªëc cho prompt, nh∆∞ng context t·ª´ standalone
#         else:
#             answer = qa_chain_fallback.invoke({"question": payload.question, "history": history_str})
#     # L∆∞u l·ªãch s·ª≠
#     history.add_message(HumanMessage(content=payload.question))
#     history.add_message(AIMessage(content=answer))
#     save_history()
#     resp = {"answer": answer.strip()}
#     if not payload.user_id and not payload.session_id:
#         resp["session_id"] = session_id
#     return resp
# @app.get("/my_chat_history")
# async def get_my_chat_history(user_id: str = None, session_id: str = None):
#     # Frontend g·ª≠i user_id (ƒë√£ ƒëƒÉng nh·∫≠p) ho·∫∑c session_id (kh√°ch v√£ng lai)
#     if user_id:
#         sid = f"user_{user_id}"
#     elif session_id:
#         sid = session_id
#     else:
#         raise HTTPException(400, "Thi·∫øu user_id ho·∫∑c session_id")
   
#     history = get_session_history(sid)
#     messages = []
#     for msg in history.messages:
#         role = "user" if isinstance(msg, HumanMessage) else "ai"
#         messages.append({"role": role, "content": msg.content})
   
#     return {"messages": messages}

# main.py ‚Äì PHI√äN B·∫¢N T·ªêI ∆ØU HO√ÄN CH·ªàNH (copy v√† ch·∫°y lu√¥n)
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import uvicorn
import os
from pathlib import Path
import uuid
import json
from functools import lru_cache
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_core.runnables import RunnableParallel
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ==========================================================
# APP + CORS
# ==========================================================
app = FastAPI(title="Shop C·∫ßu L√¥ng AI ‚Äì Retrieval Si√™u Ch√≠nh X√°c")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================================
# CONFIG
# ==========================================================
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-72fc18a871824e58a910a499f281512c")
DB_FOLDER = Path("faiss_shopcaulong")
DB_FOLDER.mkdir(exist_ok=True)
HISTORY_FILE = Path("chat_history.json")

vectorstore: FAISS | None = None
qa_chain = None
qa_chain_fallback = None
store: Dict[str, ChatMessageHistory] = {}
product_doc_ids = {}

# ==========================================================
# L∆ØU & LOAD L·ªäCH S·ª¨ CHAT
# ==========================================================
def load_history():
    global store
    if HISTORY_FILE.exists():
        try:
            data = json.loads(HISTORY_FILE.read_text(encoding="utf-8"))
            for session_id, messages in data.items():
                history = ChatMessageHistory()
                for msg in messages:
                    if msg["type"] == "human":
                        history.add_message(HumanMessage(content=msg["content"]))
                    else:
                        history.add_message(AIMessage(content=msg["content"]))
                store[session_id] = history
            print(f"ƒê√£ kh√¥i ph·ª•c l·ªãch s·ª≠ c·ªßa {len(store)} phi√™n chat")
        except Exception as e:
            print("L·ªói load l·ªãch s·ª≠ chat:", e)

def save_history():
    data = {}
    for session_id, history in store.items():
        data[session_id] = [
            {"type": "human" if isinstance(m, HumanMessage) else "ai", "content": m.content}
            for m in history.messages
        ]
    try:
        HISTORY_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as e:
        print("L·ªói l∆∞u l·ªãch s·ª≠ chat:", e)

def get_session_history(session_id: str) -> ChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# ==========================================================
# EMBEDDING & LLM
# ==========================================================
@lru_cache()
def get_embedding():
    openai_key = os.getenv("OPENAI_API_KEY")
    if openai_key:
        try:
            print("üîπ ƒêang s·ª≠ d·ª•ng OpenAI Embeddings (text-embedding-3-small)...")
            return OpenAIEmbeddings(
                model="text-embedding-3-small",
                api_key=openai_key,
                max_retries=2,
            )
        except Exception as e:
            print("L·ªói OpenAI Embedding, chuy·ªÉn qua HuggingFace:", e)
    print("üîπ Fallback sang HuggingFace Embedding (multilingual-e5-small)")
    return HuggingFaceEmbeddings(
        model_name="intfloat/multilingual-e5-small",
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )

@lru_cache()
def get_llm():
    print("üîπ Kh·ªüi t·∫°o DeepSeek LLM...")
    return ChatOpenAI(
        model="deepseek-chat",
        temperature=0.3,
        max_tokens=600,
        api_key=DEEPSEEK_API_KEY,
        base_url="https://api.deepseek.com",
        timeout=20,
        max_retries=2,
    )

# ==========================================================
# DATA MODELS
# ==========================================================
class SizeVariant(BaseModel):
    size: str
    stock: int

class ColorVariant(BaseModel):
    color: str
    imageUrls: List[str] = []
    sizes: List[SizeVariant]

class Product(BaseModel):
    id: int
    name: str
    description: str = ""
    price: float
    discountPrice: Optional[float] = None
    stock: int
    brandName: str
    categoryName: str
    isFeatured: bool = False
    details: List[Dict[str, Any]] = []
    colorVariants: List[ColorVariant] = []

# ==========================================================
# H√ÄM T·∫†O CHUNKS T·ªêI ∆ØU H∆†N
# ==========================================================
def create_product_documents(product: Product) -> List[Document]:
    price = product.discountPrice or product.price
    product_id = product.id
    product_url = f"http://localhost:3000/product/{product_id}"
    docs = []
    
    # ‚îÄ‚îÄ 1. Chunk t·ªïng quan v·ªõi keywords t√¨m ki·∫øm
    overview_keywords = [
        product.name,
        product.brandName,
        product.categoryName,
        "v·ª£t c·∫ßu l√¥ng" if "v·ª£t" in product.name.lower() else "",
        "gi√†y c·∫ßu l√¥ng" if "gi√†y" in product.name.lower() else "",
    ]
    
    info_text = f"{product.name} | {product.brandName} | {product.categoryName}"
    info_text += f" | Gi√°: {price:,.0f}ƒë"
    if product.discountPrice:
        info_text += f" (gi·∫£m c√≤n {product.discountPrice:,.0f}ƒë)"
    if product.description:
        info_text += f"\nM√¥ t·∫£: {product.description.strip()}"
    info_text += f"\nKeywords: {', '.join(filter(None, overview_keywords))}"
    info_text += f"\nXem chi ti·∫øt: {product_url}"
    
    docs.append(Document(
        page_content=info_text.strip(),
        metadata={
            "product_id": product_id,
            "type": "overview",
            "url": product_url
        }
    ))
    
    # ‚îÄ‚îÄ 2. Chunk bi·∫øn th·ªÉ m√†u + size
    for cv in product.colorVariants or []:
        color = (cv.color or "kh√¥ng m√†u").strip()
        available_sizes = [s.size for s in (cv.sizes or []) if s.stock > 0]
        if available_sizes:
            sizes_str = ", ".join(available_sizes)
            variant_text = (
                f"{product.name} m√†u {color} c√≤n size {sizes_str} "
                f"gi√° {price:,.0f}ƒë. Xem chi ti·∫øt: {product_url}"
            )
            docs.append(Document(
                page_content=variant_text,
                metadata={
                    "product_id": product_id,
                    "type": "variant",
                    "color": color,
                    "url": product_url
                }
            ))
    
    # 3.T·∫°o nhi·ªÅu chunks cho details v·ªõi keywords phong ph√∫
    all_details_text = []
    
    for idx, detail in enumerate(product.details or [], 1):
        text = detail.get("Text")
        if not text or not isinstance(text, str) or len(text.strip()) < 10:
            continue
        all_details_text.append(text.strip())
    
    # G·ªôp to√†n b·ªô details th√†nh 1 vƒÉn b·∫£n l·ªõn
    full_details = "\n\n".join(all_details_text)
    
    if full_details:
        # A. Chunk T·ªîNG H·ª¢P to√†n b·ªô details (cho c√¢u h·ªèi t·ªïng qu√°t)
        detail_summary = f"""
CHI TI·∫æT ƒê·∫¶Y ƒê·ª¶ V·ªÄ {product.name}

{full_details}

Xem s·∫£n ph·∫©m: {product_url}
        """.strip()
        
        docs.append(Document(
            page_content=detail_summary,
            metadata={
                "product_id": product_id,
                "type": "detail_full",
                "url": product_url
            }
        ))
        
        # B. Chunk TH√îNG S·ªê K·ª∏ THU·∫¨T (tr√≠ch xu·∫•t t·ª´ details)
        tech_keywords = [
            "th√¥ng s·ªë", "tr·ªçng l∆∞·ª£ng", "ƒë·ªô c·ª©ng", "ƒëi·ªÉm c√¢n b·∫±ng", 
            "chu vi", "chi·ªÅu d√†i", "m·ª©c cƒÉng", "ƒëi·ªÉm swing"," V·∫≠t li·ªáu tr·ª•c","Chi·ªÅu d√†i t·ªïng th·ªÉ"
            "V·∫≠t li·ªáu khung", "c√¥ng ngh·ªá", "weight", "balance", "stiffness","Chi·ªÅu d√†i c√°n v·ª£t","M·ª©c cƒÉng d√¢y"
        ]
        
        tech_sections = []
        for line in full_details.split('\n'):
            if any(kw in line.lower() for kw in tech_keywords):
                tech_sections.append(line.strip())
        
        if tech_sections:
            tech_content = f"""
TH√îNG S·ªê K·ª∏ THU·∫¨T CHI TI·∫æT - {product.name}

{chr(10).join(tech_sections)}

Keywords: th√¥ng s·ªë k·ªπ thu·∫≠t, specifications, ƒë·ªô c·ª©ng, tr·ªçng l∆∞·ª£ng, c√¢n n·∫∑ng, ƒëi·ªÉm c√¢n b·∫±ng, k√≠ch th∆∞·ªõc
Xem ƒë·∫ßy ƒë·ªß: {product_url}
            """.strip()
            
            docs.append(Document(
                page_content=tech_content,
                metadata={
                    "product_id": product_id,
                    "type": "detail_specs",
                    "url": product_url
                }
            ))
        
        # C. Chunk C√îNG NGH·ªÜ (n·∫øu c√≥)
        tech_blocks = []
        for text in all_details_text:
            if "c√¥ng ngh·ªá" in text.lower() or "technology" in text.lower():
                tech_blocks.append(text)
        
        if tech_blocks:
            tech_content = f"""
C√îNG NGH·ªÜ √ÅP D·ª§NG TR√äN {product.name}

{chr(10).join(tech_blocks)}

Keywords: c√¥ng ngh·ªá, technology, innovation, t√≠nh nƒÉng
Xem chi ti·∫øt: {product_url}
            """.strip()
            
            docs.append(Document(
                page_content=tech_content,
                metadata={
                    "product_id": product_id,
                    "type": "detail_tech",
                    "url": product_url
                }
            ))
        
        # D. Chunk ƒê·ªêI T∆Ø·ª¢NG S·ª¨ D·ª§NG (n·∫øu c√≥)
        target_blocks = []
        for text in all_details_text:
            if any(kw in text.lower() for kw in ["ph√π h·ª£p", "ƒë·ªëi t∆∞·ª£ng", "ng∆∞·ªùi ch∆°i", "tr√¨nh ƒë·ªô"]):
                target_blocks.append(text)
        
        if target_blocks:
            target_content = f"""
ƒê·ªêI T∆Ø·ª¢NG PH√ô H·ª¢P V·ªöI {product.name}

{chr(10).join(target_blocks)}

Keywords: ph√π h·ª£p, ƒë·ªëi t∆∞·ª£ng, ng∆∞·ªùi ch∆°i, tr√¨nh ƒë·ªô, level
Xem th√™m: {product_url}
            """.strip()
            
            docs.append(Document(
                page_content=target_content,
                metadata={
                    "product_id": product_id,
                    "type": "detail_target",
                    "url": product_url
                }
            ))
    
    return docs

# ==========================================================
# X√ìA CHUNKS
# ==========================================================
def delete_product_chunks(product_id: int) -> int:
    if not vectorstore or vectorstore.index.ntotal == 0:
        return 0
    if product_id in product_doc_ids:
        ids_to_delete = product_doc_ids[product_id]
        vectorstore.delete(ids_to_delete)
        del product_doc_ids[product_id]
        return len(ids_to_delete)
    
    ids_to_delete = []
    for i in range(vectorstore.index.ntotal):
        doc_id = vectorstore.index_to_docstore_id[i]
        doc = vectorstore.docstore.search(doc_id)
        if isinstance(doc, Document) and doc.metadata.get("product_id") == product_id:
            ids_to_delete.append(doc_id)
    if ids_to_delete:
        vectorstore.delete(ids_to_delete)
    return len(ids_to_delete)

# ==========================================================
# QUERY EXPANSION - M·ªü r·ªông query v·ªõi t·ª´ ƒë·ªìng nghƒ©a
# ==========================================================
def expand_query(original_query: str) -> str:
    """
    M·ªü r·ªông query v·ªõi c√°c t·ª´ ƒë·ªìng nghƒ©a v√† li√™n quan
    """
    expansions = {
        "th√¥ng s·ªë": ["th√¥ng s·ªë k·ªπ thu·∫≠t", "specifications", "specs", "ƒë·ªô c·ª©ng", "tr·ªçng l∆∞·ª£ng", "c√¢n n·∫∑ng", "ƒëi·ªÉm c√¢n b·∫±ng"],
        "c√¥ng ngh·ªá": ["technology", "t√≠nh nƒÉng", "innovation", "c·∫£i ti·∫øn"],
        "ph√π h·ª£p": ["ƒë·ªëi t∆∞·ª£ng", "ng∆∞·ªùi ch∆°i", "tr√¨nh ƒë·ªô", "suitable for"],
        "gi√°": ["gi√° b√°n", "price", "gi√° ti·ªÅn", "bao nhi√™u ti·ªÅn"],
        "m√†u": ["m√†u s·∫Øc", "color", "ph·ªëi m√†u"],
        "size": ["k√≠ch th∆∞·ªõc", "k√≠ch c·ª°", "s·ªë ƒëo"],
    }
    
    query_lower = original_query.lower()
    expanded_terms = [original_query]
    
    for keyword, synonyms in expansions.items():
        if keyword in query_lower:
            expanded_terms.extend(synonyms)
    
    return " ".join(expanded_terms)

# ==========================================================
# PROMPTS
# ==========================================================
template_with_products = """
B·∫°n l√† Linh ‚Äì nh√¢n vi√™n t∆∞ v·∫•n c·ªßa Shop C·∫ßu L√¥ng Pro.

D·ªÆ LI·ªÜU S·∫¢N PH·∫®M TRONG KHO:
{context}

L·ªäCH S·ª¨ H·ªòI THO·∫†I G·∫¶N ƒê√ÇY:
{history}

C√ÇU H·ªéI C·ª¶A KH√ÅCH:
{question}

NGUY√äN T·∫ÆC B·∫ÆT BU·ªòC:
1. Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n D·ªÆ LI·ªÜU S·∫¢N PH·∫®M TRONG KHO b√™n tr√™n.
2. KH√îNG s·ª≠ d·ª•ng ki·∫øn th·ª©c b√™n ngo√†i d·ªØ li·ªáu ƒë√£ cung c·∫•p.
3. N·∫øu d·ªØ li·ªáu KH√îNG ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi:
   - Ph·∫£i n√≥i r√µ: "Hi·ªán shop ch∆∞a c√≥ ƒë·ªß th√¥ng tin cho n·ªôi dung n√†y".
   - KH√îNG suy ƒëo√°n, KH√îNG b·ªãa.
4. N·∫øu d·ªØ li·ªáu ch·ªâ tr·∫£ l·ªùi ƒë∆∞·ª£c m·ªôt ph·∫ßn:
   - Ch·ªâ tr·∫£ l·ªùi ph·∫ßn c√≥ d·ªØ li·ªáu.
   - Ph·∫ßn c√≤n thi·∫øu ph·∫£i n√≥i r√µ l√† ch∆∞a c√≥ th√¥ng tin.
5. Khi tr√≠ch link, Ch·ªâ d√πng ƒë√∫ng link xu·∫•t hi·ªán trong d·ªØ li·ªáu: [xem chi ti·∫øt](URL)
6. ∆Øu ti√™n d√πng c√°c c·ª•m:
   - "D·ª±a tr√™n d·ªØ li·ªáu shop ƒëang c√≥..."
   - "Theo th√¥ng tin hi·ªán t·∫°i c·ªßa shop..."
   - "Trong h·ªá th·ªëng c·ªßa shop..."

C√ÅCH TR·∫¢ L·ªúI:
- Gi·ªçng ƒëi·ªáu th√¢n thi·ªán, t·ª± nhi√™n, chuy√™n nghi·ªáp
- G·ª£i √Ω t·ªëi ƒëa 3 s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t (n·∫øu c√≥)
- G·ªôp m√†u/size c·ªßa c√πng m·ªôt s·∫£n ph·∫©m
- V·ªõi th√¥ng s·ªë k·ªπ thu·∫≠t: tr√≠ch ƒë√∫ng t·ª´ ph·∫ßn chi ti·∫øt
- C√≥ th·ªÉ k·∫øt th√∫c b·∫±ng 1 c√¢u h·ªèi g·ª£i √Ω nh·∫π (kh√¥ng √©p mua)

V√ç D·ª§:
C√¢u h·ªèi: "V·ª£t n√†y c√≥ ph√π h·ª£p ng∆∞·ªùi m·ªõi kh√¥ng?"
Tr·∫£ l·ªùi:
"D·ª±a tr√™n d·ªØ li·ªáu shop ƒëang c√≥, m·∫´u v·ª£t n√†y c√≥ tr·ªçng l∆∞·ª£ng nh·∫π v√† th√¢n v·ª£t kh√¥ng qu√° c·ª©ng,
ph√π h·ª£p cho ng∆∞·ªùi m·ªõi ch∆°i ho·∫∑c ch∆°i phong tr√†o."

C√¢u h·ªèi: "V·ª£t n√†y ƒë√°nh c√≥ s∆∞·ªõng kh√¥ng?"
Tr·∫£ l·ªùi:
"Hi·ªán shop ch∆∞a c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° c·∫£m gi√°c ƒë√°nh th·ª±c t·∫ø c·ªßa s·∫£n ph·∫©m n√†y.
N·∫øu b·∫°n cho Linh bi·∫øt tr√¨nh ƒë·ªô ch∆°i, m√¨nh s·∫Ω t∆∞ v·∫•n ch√≠nh x√°c h∆°n nh√©."

TR·∫¢ L·ªúI:

"""

template_fallback = """
B·∫°n l√† Linh ‚Äì tr·ª£ l√Ω th√¢n thi·ªán c·ªßa Shop C·∫ßu L√¥ng Pro.

L·ªäCH S·ª¨ TR√í CHUY·ªÜN G·∫¶N ƒê√ÇY:
{history}

C√ÇU H·ªéI HO·∫∂C TIN NH·∫ÆN M·ªöI NH·∫§T:
{question}

T√åNH HU·ªêNG:
Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu s·∫£n ph·∫©m ph√π h·ª£p trong h·ªá th·ªëng shop.

NGUY√äN T·∫ÆC:
1. ƒê√¢y l√† tr·∫£ l·ªùi mang t√≠nh tr√≤ chuy·ªán v√† tham kh·∫£o, KH√îNG d·ª±a tr√™n d·ªØ li·ªáu shop.
2. KH√îNG kh·∫≥ng ƒë·ªãnh tuy·ªát ƒë·ªëi, KH√îNG n√≥i nh∆∞ th√¥ng tin ch√≠nh th·ª©c c·ªßa shop.
3. N·∫øu chia s·∫ª √Ω ki·∫øn ho·∫∑c kinh nghi·ªám, c·∫ßn n√≥i r√µ t√≠nh tham kh·∫£o.

C√ÅCH TR·∫¢ L·ªúI:
- Tr√≤ chuy·ªán t·ª± nhi√™n nh∆∞ ƒëang chat v·ªõi b·∫°n
- C√≥ th·ªÉ chia s·∫ª ki·∫øn th·ª©c chung ho·∫∑c kinh nghi·ªám ph·ªï bi·∫øn
- D√πng c√°c c·ª•m:
  - "M√¨nh chia s·∫ª ·ªü g√≥c ƒë·ªô tham kh·∫£o nh√©..."
  - "Theo kinh nghi·ªám chung th√¨..."
  - "√ù ki·∫øn c√° nh√¢n c·ªßa m√¨nh l√†..."
- Kh√¥ng spam emoji
- K·∫øt th√∫c b·∫±ng c√¢u h·ªèi ho·∫∑c g·ª£i √Ω nh·∫π ƒë·ªÉ ti·∫øp t·ª•c cu·ªôc tr√≤ chuy·ªán

V√ç D·ª§:
C√¢u h·ªèi: "D√¢y m·∫£nh c√≥ ƒë√°nh m·∫°nh h∆°n kh√¥ng?"
Tr·∫£ l·ªùi:
"M√¨nh chia s·∫ª ·ªü g√≥c ƒë·ªô tham kh·∫£o th√¥i nha üòä
D√¢y m·∫£nh th∆∞·ªùng cho c·∫£m gi√°c c·∫ßu t·ªët h∆°n, nh∆∞ng ƒë·ªïi l·∫°i s·∫Ω d·ªÖ ƒë·ª©t h∆°n so v·ªõi d√¢y d√†y."

TR·∫¢ L·ªúI:

"""

template_rewrite = """
D·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i:
{history}

V√† c√¢u h·ªèi hi·ªán t·∫°i c·ªßa kh√°ch:
{question}

H√£y vi·∫øt l·∫°i c√¢u h·ªèi th√†nh M·ªòT c√¢u h·ªèi ƒë·ªôc l·∫≠p, ƒë·∫ßy ƒë·ªß ng·ªØ c·∫£nh, KH√îNG d√πng c√°c t·ª´ m∆° h·ªì nh∆∞:
"c√°i n√†y", "v·ª£t tr√™n", "s·∫£n ph·∫©m ƒë√≥", "n√≥", "lo·∫°i kia"...

QUY T·∫ÆC:
- N·∫øu l·ªãch s·ª≠ c√≥ nh·∫Øc t√™n s·∫£n ph·∫©m ‚Üí ph·∫£i ƒë∆∞a t√™n s·∫£n ph·∫©m v√†o c√¢u h·ªèi m·ªõi
- C√≥ th·ªÉ b·ªï sung t·ª´ ƒë·ªìng nghƒ©a ƒë·ªÉ d·ªÖ truy xu·∫•t d·ªØ li·ªáu
  (v√≠ d·ª•: th√¥ng s·ªë = specs = tr·ªçng l∆∞·ª£ng = ƒë·ªô c·ª©ng)
- N·∫øu c√¢u h·ªèi ƒë√£ ƒë·ªß r√µ v√† ƒë·ªôc l·∫≠p ‚Üí gi·ªØ nguy√™n

V√ç D·ª§:
L·ªãch s·ª≠: Kh√°ch ƒëang n√≥i v·ªÅ v·ª£t Yonex Astrox 99  
C√¢u h·ªèi: "Th√¥ng s·ªë k·ªπ thu·∫≠t c·ªßa v·ª£t tr√™n l√† g√¨?"  
Vi·∫øt l·∫°i: "Th√¥ng s·ªë k·ªπ thu·∫≠t c·ªßa v·ª£t Yonex Astrox 99 l√† g√¨?"

Ch·ªâ tr·∫£ v·ªÅ c√¢u h·ªèi ƒë√£ vi·∫øt l·∫°i, KH√îNG gi·∫£i th√≠ch th√™m.

"""

prompt_with_products = ChatPromptTemplate.from_template(template_with_products)
prompt_fallback = ChatPromptTemplate.from_template(template_fallback)
prompt_rewrite = ChatPromptTemplate.from_template(template_rewrite)

# ==========================================================
# BUILD QA CHAIN
# ==========================================================
def build_qa_chain():
    global qa_chain, qa_chain_fallback
    if not vectorstore or vectorstore.index.ntotal == 0:
        qa_chain = None
        qa_chain_fallback = None
        return
    
    # Retriever v·ªõi MMR ƒë·ªÉ tƒÉng ƒëa d·∫°ng k·∫øt qu·∫£
    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 20,
            "fetch_k": 50,
            "lambda_mult": 0.7
        }
    )
    
    # Chain ch√≠nh
    qa_chain = (
        RunnableParallel({
            "context": lambda x: "\n\n".join([d.page_content for d in retriever.invoke(x["question"])]),
            "question": lambda x: x["question"],
            "history": lambda x: x.get("history", "Ch∆∞a c√≥ l·ªãch s·ª≠"),
        })
        | prompt_with_products
        | get_llm()
        | StrOutputParser()
    )
    
    # Chain fallback
    qa_chain_fallback = (
        RunnableParallel({
            "question": lambda x: x["question"],
            "history": lambda x: x.get("history", "Ch∆∞a c√≥ l·ªãch s·ª≠"),
        })
        | prompt_fallback
        | get_llm()
        | StrOutputParser()
    )

# ==========================================================
# ROUTES
# ==========================================================
@app.get("/")
async def root():
    total = vectorstore.index.ntotal if vectorstore else 0
    return {
        "message": "Linh ƒëang online v·ªõi retrieval si√™u ch√≠nh x√°c!",
        "chunks": total,
        "active_sessions": len(store)
    }

@app.post("/debug_chunks")
async def debug_chunks_post(
    limit: int = 50,
    product_id: Optional[int] = None,
    include_metadata: bool = True
):
    if not vectorstore or vectorstore.index.ntotal == 0:
        return {
            "total_chunks_in_db": 0,
            "returned_chunks": 0,
            "chunks": [],
            "message": "Ch∆∞a c√≥ d·ªØ li·ªáu"
        }
    
    total = vectorstore.index.ntotal
    results = []
    
    for i in range(min(limit, total)):
        doc_id = vectorstore.index_to_docstore_id[i]
        doc = vectorstore.docstore.search(doc_id)
        
        if isinstance(doc, Document):
            item = {"index": i, "content": doc.page_content}
            if include_metadata:
                item["metadata"] = doc.metadata
            
            if product_id is not None:
                if doc.metadata.get("product_id") != product_id:
                    continue
            
            results.append(item)
    
    return {
        "total_chunks_in_db": total,
        "returned_chunks": len(results),
        "chunks": results
    }

@app.post("/add_product")
async def add_product(product: Product):
    global vectorstore
    
    delete_product_chunks(product.id)
    docs = create_product_documents(product)
    
    if vectorstore is None:
        vectorstore = FAISS.from_documents(docs, get_embedding())
    else:
        doc_ids = vectorstore.add_documents(docs)
        product_doc_ids[product.id] = doc_ids
    
    vectorstore.save_local(str(DB_FOLDER))
    build_qa_chain()
    
    return {"status": "OK", "message": f"ƒê√£ th√™m {product.name}", "chunks": len(docs)}

@app.post("/update_product")
async def update_product(product: Product):
    global vectorstore
    
    print(f"[AI] Nh·∫≠n y√™u c·∫ßu update s·∫£n ph·∫©m ID: {product.id} - {product.name}")
    
    delete_product_chunks(product.id)
    docs = create_product_documents(product)
    
    if vectorstore is None:
        vectorstore = FAISS.from_documents(docs, get_embedding())
    else:
        doc_ids = vectorstore.add_documents(docs)
        product_doc_ids[product.id] = doc_ids
    
    vectorstore.save_local(str(DB_FOLDER))
    build_qa_chain()
    
    print(f"[AI] ƒê√£ chunk {len(docs)} m·∫©u cho s·∫£n ph·∫©m {product.name}")
    
    return {"status": "OK", "message": f"ƒê√£ c·∫≠p nh·∫≠t {product.name}", "chunks": len(docs)}

@app.post("/delete_product")
async def delete_product(product_id: int):
    deleted = delete_product_chunks(product_id)
    
    if deleted == 0:
        raise HTTPException(404, "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m")
    
    vectorstore.save_local(str(DB_FOLDER))
    build_qa_chain()
    
    return {"status": "OK", "deleted_chunks": deleted}

@app.post("/reindex_all")
async def rebuild(products: List[Product]):
    global vectorstore, product_doc_ids
    
    product_doc_ids = {}
    all_docs = []
    
    for p in products:
        docs = create_product_documents(p)
        all_docs.extend(docs)
        product_doc_ids[p.id] = []
    
    vectorstore = FAISS.from_documents(all_docs, get_embedding())
    
    current_index = 0
    for p in products:
        docs_count = len(create_product_documents(p))
        ids = [vectorstore.index_to_docstore_id[current_index + i] for i in range(docs_count)]
        product_doc_ids[p.id] = ids
        current_index += docs_count
    
    vectorstore.save_local(str(DB_FOLDER))
    build_qa_chain()
    
    return {"status": "OK", "chunks": len(all_docs)}

# ==================== CHAT PAYLOAD ====================
class ChatPayload(BaseModel):
    question: str
    session_id: Optional[str] = None
    user_id: Optional[str] = None

@app.post("/chat")
async def chat(payload: ChatPayload):
    if not qa_chain:
        raise HTTPException(500, "Ch∆∞a c√≥ d·ªØ li·ªáu s·∫£n ph·∫©m!")
    
    # X√°c ƒë·ªãnh session_id
    if payload.user_id:
        session_id = f"user_{payload.user_id}"
    elif payload.session_id:
        session_id = payload.session_id
    else:
        session_id = str(uuid.uuid4())
    
    history = get_session_history(session_id)
    history_str = "\n".join(
        f"{'Kh√°ch' if isinstance(m, HumanMessage) else 'Linh'}: {m.content}"
        for m in history.messages[-10:]
    ) or "Ch∆∞a c√≥ l·ªãch s·ª≠"
    
    # Query Classification
    classify_prompt = ChatPromptTemplate.from_template("""
        Ph√¢n lo·∫°i c√¢u h·ªèi: "{question}"
        - N·∫øu li√™n quan ƒë·∫øn s·∫£n ph·∫©m c·∫ßu l√¥ng (v·ª£t, gi√†y, c∆∞·ªõc, t∆∞ v·∫•n mua, th√¥ng s·ªë k·ªπ thu·∫≠t): "relevant"
        - N·∫øu kh√¥ng li√™n quan: "irrelevant"
        Ch·ªâ tr·∫£ "relevant" ho·∫∑c "irrelevant", kh√¥ng gi·∫£i th√≠ch.
    """)
    classify_chain = classify_prompt | get_llm() | StrOutputParser()
    classification = classify_chain.invoke({"question": payload.question}).strip().lower()
    
    if classification == "irrelevant":
        print("Query kh√¥ng li√™n quan ‚Üí fallback")
        answer = qa_chain_fallback.invoke({"question": payload.question, "history": history_str})
    else:
        # Rewrite query + Expand query
        rewrite_chain = prompt_rewrite | get_llm() | StrOutputParser()
        standalone_question = rewrite_chain.invoke({
            "question": payload.question, 
            "history": history_str
        }).strip()
        
        # M·ªü r·ªông query v·ªõi t·ª´ ƒë·ªìng nghƒ©a
        expanded_query = expand_query(standalone_question)
        
        print(f"Query g·ªëc: {payload.question}")
        print(f"Standalone: {standalone_question}")
        print(f"Expanded: {expanded_query}")
        
        # Retrieve v·ªõi expanded query
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 20, "fetch_k": 50, "lambda_mult": 0.7}
        )
        
        try:
            retrieved_docs = retriever.invoke(expanded_query)
        except:
            retrieved_docs = retriever.invoke(standalone_question)
        
        context_text = "\n\n".join([d.page_content for d in retrieved_docs])
        
        # Ki·ªÉm tra xem c√≥ th√¥ng tin s·∫£n ph·∫©m kh√¥ng
        product_keywords = ["v·ª£t", "gi√†y", "c∆∞·ªõc", "yonex", "victor", "lining", "th√¥ng s·ªë", "c√¥ng ngh·ªá"]
        has_products = len(retrieved_docs) > 0 and any(kw.lower() in context_text.lower() for kw in product_keywords)
        
        print(f"S·ªë docs: {len(retrieved_docs)} | C√≥ s·∫£n ph·∫©m: {has_products}")
        
        if has_products:
            answer = qa_chain.invoke({
                "question": payload.question, 
                "history": history_str, 
                "context": context_text
            })
        else:
            answer = qa_chain_fallback.invoke({"question": payload.question, "history": history_str})
    
    # L∆∞u l·ªãch s·ª≠
    history.add_message(HumanMessage(content=payload.question))
    history.add_message(AIMessage(content=answer))
    save_history()
    
    resp = {"answer": answer.strip()}
    if not payload.user_id and not payload.session_id:
        resp["session_id"] = session_id
    
    return resp

@app.get("/my_chat_history")
async def get_my_chat_history(user_id: str = None, session_id: str = None):
    if user_id:
        sid = f"user_{user_id}"
    elif session_id:
        sid = session_id
    else:
        raise HTTPException(400, "Thi·∫øu user_id ho·∫∑c session_id")
    
    history = get_session_history(sid)
    messages = []
    for msg in history.messages:
        role = "user" if isinstance(msg, HumanMessage) else "ai"
        messages.append({"role": role, "content": msg.content})
    
    return {"messages": messages}

# ==========================================================
# STARTUP & SHUTDOWN
# ==========================================================
@app.on_event("startup")
async def startup():
    global vectorstore
    if (DB_FOLDER / "index.faiss").exists():
        try:
            vectorstore = FAISS.load_local(
                str(DB_FOLDER), get_embedding(), allow_dangerous_deserialization=True
            )
            print(f"Load FAISS th√†nh c√¥ng: {vectorstore.index.ntotal} chunks")
        except Exception as e:
            print("Load FAISS l·ªói:", e)
    if vectorstore is None:
        vectorstore = FAISS.from_texts(["Shop ƒëang kh·ªüi ƒë·ªông..."], get_embedding())
        vectorstore.save_local(str(DB_FOLDER))
    load_history()
    build_qa_chain()
    print("Linh ƒë√£ s·∫µn s√†ng ‚Äì nh·ªõ h·∫øt kh√°ch c≈©, si√™u chuy√™n nghi·ªáp!")
@app.on_event("shutdown")
async def shutdown():
    save_history()
    print("ƒê√£ l∆∞u to√†n b·ªô l·ªãch s·ª≠ chat tr∆∞·ªõc khi t·∫Øt server!")
if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
